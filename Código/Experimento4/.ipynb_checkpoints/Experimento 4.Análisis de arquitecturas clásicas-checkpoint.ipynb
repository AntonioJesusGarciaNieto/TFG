{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsBFD7icF6Xc"
   },
   "source": [
    "# Experimento 4 : Análisis de arquitecturas clásicas.\n",
    "\n",
    "En este experimento estudiaremos el comportamiento de las arquitecturas de redes neuronales más relevante a lo largo de la historia de las CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RxC7JJwlFuvk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkqu4FPPGQgV"
   },
   "source": [
    "## Definición de rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CZazLFjjGZVf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antgarnie/Escritorio/TFG/Datos\n",
      "/home/antgarnie/Escritorio/TFG/Datos/HAM10000_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "#Rutas de los datos.\n",
    " \n",
    "data_dir = os.path.dirname(os.path.realpath(\"../TFG/Datos/HAM10000_metadata.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "csv_path = os.path.realpath(data_dir + \"/HAM10000_metadata.csv\")\n",
    "\n",
    "#Variables globales\n",
    "\n",
    "altura = 128\n",
    "longitud = 128\n",
    "clases = 7\n",
    "\n",
    "\n",
    "print(data_dir)\n",
    "\n",
    "print(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD9w48fEGfkF"
   },
   "source": [
    "## Creación del marco de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "pf0IBVhhGehu",
    "outputId": "af59739a-413e-4a7d-c5ac-b775ab675e5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path          cell_type  \\\n",
       "0  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "1  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "2  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "3  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "4  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "\n",
       "   cell_type_idx  \n",
       "0              2  \n",
       "1              2  \n",
       "2              2  \n",
       "3              2  \n",
       "4              2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inicializando el dataFrame\n",
    "\n",
    "dataFrame=pd.read_csv(csv_path)\n",
    "\n",
    "#Mezclando carpetas.\n",
    "\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "\n",
    "# Inicializando diccionario de categorías\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "#Añadiendo columnas al dataFrame para que sea más legible.\n",
    "\n",
    "dataFrame['path'] = dataFrame['image_id'].map(imageid_path_dict.get)\n",
    "dataFrame['cell_type'] = dataFrame['dx'].map(lesion_type_dict.get) \n",
    "dataFrame['cell_type_idx'] = pd.Categorical(dataFrame['cell_type']).codes\n",
    "dataFrame.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT1Py3CnE0bT",
    "outputId": "aea7fc1b-b1d9-42af-caa5-40293bbc2136"
   },
   "source": [
    "## Preparación de la red\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_network(nn_base_arch):\n",
    "\n",
    "    #Familia VGG\n",
    "    if nn_base_arch == 'VGG16':\n",
    "        nn = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))   \n",
    "    if nn_base_arch == 'VGG19':  \n",
    "        nn = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    \n",
    "    #Familia MobileNet\n",
    "    if nn_base_arch == 'MNv1':\n",
    "        nn = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    if nn_base_arch == 'MNv2':\n",
    "        nn = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "        \n",
    "        \n",
    "    #Entradas mayor de 75 x 75    \n",
    "    if nn_base_arch == 'IV3':\n",
    "        nn = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "        \n",
    "    #Entradas  mayor de 72 x 72\n",
    "    if nn_base_arch == 'Xception':\n",
    "        nn = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "          \n",
    "    if nn_base_arch == 'ENB4':\n",
    "        nn = tf.keras.applications.EfficientNetB4(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    if nn_base_arch == 'ResNet50':  \n",
    "        nn = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    \n",
    "    if nn_base_arch == 'ResNet152v2':  \n",
    "        nn = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    return nn\n",
    "\n",
    "def build(nn):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(nn)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(clases,activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 22,852,519\n",
      "Trainable params: 22,818,087\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 15,764,423\n",
      "Trainable params: 15,764,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn_base_arch = 'IV3'\n",
    "nn = select_network(nn_base_arch)\n",
    "modelIV3 = build(nn)\n",
    "\n",
    "nn_base_arch = 'VGG16'\n",
    "nn = select_network(nn_base_arch)\n",
    "modelVGG = build(nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembled_models(modelIV3,modelVGG,clases = 7,input_shape=(128, 128, 3)):\n",
    "    image = tf.keras.layers.Input(shape=input_shape)\n",
    "    x  =  modelIV3(image)\n",
    "    x1 = modelVGG(image)\n",
    "    x = tf.keras.layers.concatenate([x,x1])\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Dense(clases,activation='softmax')(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=image, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "657/657 [==============================] - 93s 141ms/step - loss: 1.6867 - accuracy: 0.3210 - val_loss: 1.4136 - val_accuracy: 0.4252\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 93s 142ms/step - loss: 1.3466 - accuracy: 0.4671 - val_loss: 1.1196 - val_accuracy: 0.6088\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 93s 142ms/step - loss: 1.1123 - accuracy: 0.5947 - val_loss: 0.8707 - val_accuracy: 0.7286\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 95s 144ms/step - loss: 0.9752 - accuracy: 0.6641 - val_loss: 0.7343 - val_accuracy: 0.7463\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 96s 146ms/step - loss: 0.7826 - accuracy: 0.7216 - val_loss: 0.5823 - val_accuracy: 0.7626\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 94s 144ms/step - loss: 0.6554 - accuracy: 0.7477 - val_loss: 0.5227 - val_accuracy: 0.7884\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 92s 140ms/step - loss: 0.6119 - accuracy: 0.7687 - val_loss: 1.4112 - val_accuracy: 0.5503\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 93s 142ms/step - loss: 0.8414 - accuracy: 0.7060 - val_loss: 0.6940 - val_accuracy: 0.7510\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 92s 140ms/step - loss: 0.6833 - accuracy: 0.7454 - val_loss: 0.5361 - val_accuracy: 0.7891\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.5501 - accuracy: 0.7886\n"
     ]
    }
   ],
   "source": [
    "model = ensembled_models(modelIV3,modelVGG,clases = 7,input_shape=(128, 128, 3))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, mode = 'min') \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model = model.fit(x_train, y_train,validation_data=(x_validation, y_validation),epochs=20,callbacks=[earlyStopping],batch_size = BATCH_SIZE)\n",
    "evaluation = model.model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se procede a crear un método que permita balancear la carga de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NO6Snfw-KYe4"
   },
   "outputs": [],
   "source": [
    "def balanced_dataset(df):\n",
    "    df_balanced = pd.DataFrame()\n",
    "    #df = pd.DataFrame()\n",
    "    \n",
    "    for cat in df['cell_type_idx'].unique():\n",
    "        temp = resample(df[df['cell_type_idx'] == cat], \n",
    "                        replace=True,     # sample with replacement\n",
    "                        n_samples=10,   # to match majority class\n",
    "                        random_state=123) # reproducible results\n",
    "\n",
    "        # Combine majority class with upsampled minority class\n",
    "        df_balanced = pd.concat([df_balanced, temp])\n",
    " \n",
    "    df_balanced['cell_type'].value_counts()\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "def load_img_data(size, df, balanced=False):\n",
    "    \"\"\"\n",
    "        ..\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    img_h, img_w = size, size\n",
    "    imgs = []\n",
    "    \n",
    "    if balanced:\n",
    "        df = balanced_dataset(df)\n",
    "    \n",
    "    image_paths = list(df['path'])\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        #img = np.asarray(Image.open(image_paths[i]).resize((size,size)))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    #imgs = imgs.astype(np.float32) / 255.\n",
    "    \n",
    "    return imgs, df['cell_type_idx'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos y creamos los casos a experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_general_data():\n",
    "    \n",
    "    imgs, target = load_img_data(altura, dataFrame, balanced=True)\n",
    "    \n",
    "    x_train, x_transferLearning, y_train, y_transferLearning = train_test_split(imgs, target, test_size=0.60)\n",
    "       \n",
    "    source_data = [ x_transferLearning , y_transferLearning ]\n",
    "    target_data = [ x_train , y_train ]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(target_data[0], target_data[1], test_size=0.70)\n",
    "    \n",
    "    train_data = [x_train,y_train]\n",
    "    test_data = [x_test,y_test]\n",
    "    \n",
    "    return source_data,train_data,test_data\n",
    "\n",
    "\n",
    "def get_data_for_ex(source_data,train_data,test_data):\n",
    "    \n",
    "    x_train = source_data[0]\n",
    "    y_train = source_data[1]\n",
    "    \n",
    "    x_retrain = train_data[0]\n",
    "    y_retrain = train_data[1]\n",
    "    \n",
    "    percent = math.floor(len(test_data[0])/100*30)\n",
    "       \n",
    "    x_validation = test_data[0][0:percent]\n",
    "    y_validation = test_data[1][0:percent]\n",
    "    \n",
    "    \n",
    "    x_test = test_data[0][percent:-1]\n",
    "    y_test = test_data[1][percent:-1]\n",
    "    \n",
    "    return x_train,x_retrain,x_test,x_validation,y_train,y_retrain,y_test,y_validation\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "# Definimos 7 experimentos cada uno con un optimizador distingo y definimos el número de iteraciones          #\n",
    "###############################################################################################################\n",
    "\n",
    "ITERATIONS_PER_EXP = 5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE=0.0001\n",
    "\n",
    "\n",
    "def set_hiper_to_exp(BATCH_SIZE,EPOCHS,LEARNING_RATE):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE,amsgrad=True)  \n",
    "    return BATCH_SIZE,EPOCHS,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 146.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_data,train_data,test_data = load_general_data()\n",
    "x_train,x_retrain,x_test,x_validation,y_train,y_retrain,y_test,y_validation = get_data_for_ex(source_data,train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redistribution_of_data_for_train_historical_models(x_train, x_retrain, y_train, y_retrain):\n",
    "\n",
    "    new_x_train = np.append(x_train, x_retrain, 0)\n",
    "    new_y_train = np.append(y_train, y_retrain, 0)\n",
    "    \n",
    "    return new_x_train,new_y_train\n",
    "\n",
    "x_train,y_train = redistribution_of_data_for_train_historical_models(x_train, x_retrain, y_train, y_retrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Transfer learning phase -----\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 27,783,175\n",
      "Trainable params: 27,730,055\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Estas entrenando ResNet50 con 50\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 25s 39ms/step - loss: 1.9312 - accuracy: 0.2033 - val_loss: 1.8456 - val_accuracy: 0.2503\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.7496 - accuracy: 0.2961 - val_loss: 2.2394 - val_accuracy: 0.2102\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.5165 - accuracy: 0.4013 - val_loss: 4.7715 - val_accuracy: 0.1837\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.3641 - accuracy: 0.4617 - val_loss: 23.2983 - val_accuracy: 0.1429\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.2592 - accuracy: 0.5068 - val_loss: 6.2158 - val_accuracy: 0.2129\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.1600 - accuracy: 0.5491 - val_loss: 41.2202 - val_accuracy: 0.1497\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 36ms/step - loss: 41.9695 - accuracy: 0.1397\n",
      "-----------------------------------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3d846efed0>\n",
      "---Finetuning phase -----\n",
      "Learning Rate ->1e-05\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 52s 80ms/step - loss: 1.6455 - accuracy: 0.4740 - val_loss: 18.7096 - val_accuracy: 0.1327\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.5857 - accuracy: 0.8060 - val_loss: 0.4136 - val_accuracy: 0.8782\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.2952 - accuracy: 0.9081 - val_loss: 0.2717 - val_accuracy: 0.9259\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.1821 - accuracy: 0.9484 - val_loss: 0.2274 - val_accuracy: 0.9361\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.1146 - accuracy: 0.9715 - val_loss: 0.2053 - val_accuracy: 0.9408\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0725 - accuracy: 0.9858 - val_loss: 0.1931 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0492 - accuracy: 0.9923 - val_loss: 0.1956 - val_accuracy: 0.9456\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0405 - accuracy: 0.9925 - val_loss: 0.2008 - val_accuracy: 0.9429\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0286 - accuracy: 0.9955 - val_loss: 0.2028 - val_accuracy: 0.9456\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0237 - accuracy: 0.9967 - val_loss: 0.1992 - val_accuracy: 0.9435\n",
      "Epoch 11/20\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.0192 - accuracy: 0.9971 - val_loss: 0.2020 - val_accuracy: 0.9456\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 33ms/step - loss: 0.1884 - accuracy: 0.9417\n",
      "-----------------------------------------\n",
      "########################################################\n",
      "ResNet50 entrenamiento con TF y FT 3 bloques- Iteración 1 de 5\n",
      "########################################################\n",
      "---Transfer learning phase -----\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 27,783,175\n",
      "Trainable params: 27,730,055\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Estas entrenando ResNet50 con 50\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 25s 38ms/step - loss: 1.9654 - accuracy: 0.1512 - val_loss: 1.9436 - val_accuracy: 0.1980\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.8518 - accuracy: 0.2187 - val_loss: 2.4041 - val_accuracy: 0.1619\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.6172 - accuracy: 0.3323 - val_loss: 1.9670 - val_accuracy: 0.2864\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.5172 - accuracy: 0.3866 - val_loss: 3.4546 - val_accuracy: 0.2143\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.4064 - accuracy: 0.4342 - val_loss: 5.1382 - val_accuracy: 0.1980\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.3476 - accuracy: 0.4633 - val_loss: 16.4931 - val_accuracy: 0.1442\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 33ms/step - loss: 16.7461 - accuracy: 0.1388\n",
      "-----------------------------------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3d846c3990>\n",
      "---Finetuning phase -----\n",
      "Learning Rate ->1e-05\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 1.4161 - accuracy: 0.5486 - val_loss: 47.7378 - val_accuracy: 0.1442\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.5008 - accuracy: 0.8349 - val_loss: 0.3703 - val_accuracy: 0.8837\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.2533 - accuracy: 0.9227 - val_loss: 0.2110 - val_accuracy: 0.9333\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.1377 - accuracy: 0.9615 - val_loss: 0.1830 - val_accuracy: 0.9333\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0823 - accuracy: 0.9798 - val_loss: 0.1723 - val_accuracy: 0.9354\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0556 - accuracy: 0.9886 - val_loss: 0.1717 - val_accuracy: 0.9388\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0367 - accuracy: 0.9934 - val_loss: 0.1713 - val_accuracy: 0.9435\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0293 - accuracy: 0.9944 - val_loss: 0.1656 - val_accuracy: 0.9442\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.0233 - accuracy: 0.9972 - val_loss: 0.1695 - val_accuracy: 0.9429\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.1732 - val_accuracy: 0.9456\n",
      "Epoch 11/20\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.1727 - val_accuracy: 0.9442\n",
      "Epoch 12/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0118 - accuracy: 0.9989 - val_loss: 0.1720 - val_accuracy: 0.9449\n",
      "Epoch 13/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.1812 - val_accuracy: 0.9463\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.2015 - accuracy: 0.9478\n",
      "-----------------------------------------\n",
      "########################################################\n",
      "ResNet50 entrenamiento con TF y FT 3 bloques- Iteración 2 de 5\n",
      "########################################################\n",
      "---Transfer learning phase -----\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 27,783,175\n",
      "Trainable params: 27,730,055\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Estas entrenando ResNet50 con 50\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 25s 38ms/step - loss: 1.9451 - accuracy: 0.1736 - val_loss: 1.8660 - val_accuracy: 0.2490\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.8452 - accuracy: 0.2513 - val_loss: 1.8328 - val_accuracy: 0.2231\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.6493 - accuracy: 0.3476 - val_loss: 5.5216 - val_accuracy: 0.2497\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.4575 - accuracy: 0.4191 - val_loss: 6.7648 - val_accuracy: 0.1442\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.3443 - accuracy: 0.4732 - val_loss: 9.3920 - val_accuracy: 0.1619\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.2594 - accuracy: 0.5095 - val_loss: 2.0274 - val_accuracy: 0.1973\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.1944 - accuracy: 0.5345 - val_loss: 12.4570 - val_accuracy: 0.1476\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 12.7495 - accuracy: 0.1557\n",
      "-----------------------------------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3e3adcdd50>\n",
      "---Finetuning phase -----\n",
      "Learning Rate ->1e-05\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 50s 75ms/step - loss: 1.8063 - accuracy: 0.4478 - val_loss: 76.0821 - val_accuracy: 0.1388\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.7056 - accuracy: 0.7703 - val_loss: 0.6678 - val_accuracy: 0.8170\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3760 - accuracy: 0.8783 - val_loss: 0.3882 - val_accuracy: 0.8912\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.2221 - accuracy: 0.9330 - val_loss: 0.3075 - val_accuracy: 0.9122\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.1435 - accuracy: 0.9614 - val_loss: 0.2632 - val_accuracy: 0.9265\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.0949 - accuracy: 0.9771 - val_loss: 0.2291 - val_accuracy: 0.9347\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.0655 - accuracy: 0.9865 - val_loss: 0.2121 - val_accuracy: 0.9367\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0486 - accuracy: 0.9915 - val_loss: 0.2123 - val_accuracy: 0.9381\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.0385 - accuracy: 0.9936 - val_loss: 0.2074 - val_accuracy: 0.9415\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0311 - accuracy: 0.9950 - val_loss: 0.2150 - val_accuracy: 0.9429\n",
      "Epoch 11/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.0227 - accuracy: 0.9970 - val_loss: 0.2022 - val_accuracy: 0.9422\n",
      "Epoch 12/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0199 - accuracy: 0.9974 - val_loss: 0.2039 - val_accuracy: 0.9415\n",
      "Epoch 13/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.0166 - accuracy: 0.9980 - val_loss: 0.1992 - val_accuracy: 0.9442\n",
      "Epoch 14/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0137 - accuracy: 0.9982 - val_loss: 0.2001 - val_accuracy: 0.9429\n",
      "Epoch 15/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.0124 - accuracy: 0.9987 - val_loss: 0.1979 - val_accuracy: 0.9415\n",
      "Epoch 16/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.2019 - val_accuracy: 0.9415\n",
      "Epoch 17/20\n",
      "657/657 [==============================] - 48s 74ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 0.2021 - val_accuracy: 0.9435\n",
      "Epoch 18/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.2076 - val_accuracy: 0.9435\n",
      "Epoch 19/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0094 - accuracy: 0.9987 - val_loss: 0.2075 - val_accuracy: 0.9435\n",
      "Epoch 20/20\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.2069 - val_accuracy: 0.9435\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 35ms/step - loss: 0.2211 - accuracy: 0.9376\n",
      "-----------------------------------------\n",
      "########################################################\n",
      "ResNet50 entrenamiento con TF y FT 3 bloques- Iteración 3 de 5\n",
      "########################################################\n",
      "---Transfer learning phase -----\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 27,783,175\n",
      "Trainable params: 27,730,055\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Estas entrenando ResNet50 con 50\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 25s 38ms/step - loss: 1.9678 - accuracy: 0.1526 - val_loss: 1.9432 - val_accuracy: 0.2116\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.9152 - accuracy: 0.1881 - val_loss: 5.5874 - val_accuracy: 0.1476\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.7499 - accuracy: 0.2661 - val_loss: 4.4346 - val_accuracy: 0.0837\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.5577 - accuracy: 0.3739 - val_loss: 2.5360 - val_accuracy: 0.2456\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.4294 - accuracy: 0.4298 - val_loss: 1.7796 - val_accuracy: 0.2803\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.3143 - accuracy: 0.4771 - val_loss: 7.0704 - val_accuracy: 0.1660\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.2293 - accuracy: 0.5176 - val_loss: 4.2926 - val_accuracy: 0.1265\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 24s 37ms/step - loss: 1.1407 - accuracy: 0.5578 - val_loss: 4.0428 - val_accuracy: 0.1340\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.0714 - accuracy: 0.5824 - val_loss: 3.6382 - val_accuracy: 0.2116\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.0195 - accuracy: 0.6083 - val_loss: 4.0293 - val_accuracy: 0.1667\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 3.8549 - accuracy: 0.1837\n",
      "-----------------------------------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3d101f3d50>\n",
      "---Finetuning phase -----\n",
      "Learning Rate ->1e-05\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 1.8306 - accuracy: 0.4239 - val_loss: 73.8124 - val_accuracy: 0.1252\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.6970 - accuracy: 0.7762 - val_loss: 0.4904 - val_accuracy: 0.8374\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.3551 - accuracy: 0.8918 - val_loss: 0.2916 - val_accuracy: 0.9088\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 0.1927 - accuracy: 0.9477 - val_loss: 0.2161 - val_accuracy: 0.9265\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.1175 - accuracy: 0.9692 - val_loss: 0.2026 - val_accuracy: 0.9374\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.0763 - accuracy: 0.9836 - val_loss: 0.1922 - val_accuracy: 0.9374\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 52s 80ms/step - loss: 0.0556 - accuracy: 0.9885 - val_loss: 0.1845 - val_accuracy: 0.9429\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0381 - accuracy: 0.9937 - val_loss: 0.1868 - val_accuracy: 0.9435\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0290 - accuracy: 0.9952 - val_loss: 0.1957 - val_accuracy: 0.9408\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0226 - accuracy: 0.9978 - val_loss: 0.1970 - val_accuracy: 0.9401\n",
      "Epoch 11/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0196 - accuracy: 0.9978 - val_loss: 0.1918 - val_accuracy: 0.9442\n",
      "Epoch 12/20\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.0165 - accuracy: 0.9980 - val_loss: 0.1974 - val_accuracy: 0.9408\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 34ms/step - loss: 0.1864 - accuracy: 0.9437\n",
      "-----------------------------------------\n",
      "########################################################\n",
      "ResNet50 entrenamiento con TF y FT 3 bloques- Iteración 4 de 5\n",
      "########################################################\n",
      "---Transfer learning phase -----\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 27,783,175\n",
      "Trainable params: 27,730,055\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Estas entrenando ResNet50 con 50\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 25s 38ms/step - loss: 1.9643 - accuracy: 0.1445 - val_loss: 1.9628 - val_accuracy: 0.1469\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 25s 38ms/step - loss: 1.9264 - accuracy: 0.1814 - val_loss: 2.8623 - val_accuracy: 0.1551\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 25s 37ms/step - loss: 1.7505 - accuracy: 0.2924 - val_loss: 7.9425 - val_accuracy: 0.1497\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 25s 37ms/step - loss: 1.5147 - accuracy: 0.3926 - val_loss: 1.6187 - val_accuracy: 0.3483\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 25s 37ms/step - loss: 1.3899 - accuracy: 0.4480 - val_loss: 16.8465 - val_accuracy: 0.1449\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 25s 37ms/step - loss: 1.2824 - accuracy: 0.4928 - val_loss: 25.1377 - val_accuracy: 0.1422\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 25s 37ms/step - loss: 1.1879 - accuracy: 0.5383 - val_loss: 9.5066 - val_accuracy: 0.1340\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 25s 37ms/step - loss: 1.1093 - accuracy: 0.5705 - val_loss: 8.5008 - val_accuracy: 0.1367\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 24s 37ms/step - loss: 1.0798 - accuracy: 0.5797 - val_loss: 24.7677 - val_accuracy: 0.2789\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 33ms/step - loss: 25.8863 - accuracy: 0.2613\n",
      "-----------------------------------------\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f3c5862ad10>\n",
      "---Finetuning phase -----\n",
      "Learning Rate ->1e-05\n",
      "Epoch 1/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 1.9755 - accuracy: 0.3898 - val_loss: 45.0562 - val_accuracy: 0.1680\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.8482 - accuracy: 0.7277 - val_loss: 0.7739 - val_accuracy: 0.7939\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.4630 - accuracy: 0.8548 - val_loss: 0.4253 - val_accuracy: 0.8796\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.2728 - accuracy: 0.9209 - val_loss: 0.3282 - val_accuracy: 0.9122\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.1745 - accuracy: 0.9560 - val_loss: 0.2743 - val_accuracy: 0.9272\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.1213 - accuracy: 0.9705 - val_loss: 0.2233 - val_accuracy: 0.9361\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0824 - accuracy: 0.9827 - val_loss: 0.2359 - val_accuracy: 0.9374\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0621 - accuracy: 0.9864 - val_loss: 0.2265 - val_accuracy: 0.9388\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0486 - accuracy: 0.9915 - val_loss: 0.2341 - val_accuracy: 0.9367\n",
      "Epoch 10/20\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.0373 - accuracy: 0.9930 - val_loss: 0.2232 - val_accuracy: 0.9422\n",
      "Epoch 11/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0303 - accuracy: 0.9954 - val_loss: 0.2396 - val_accuracy: 0.9422\n",
      "Epoch 12/20\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.0272 - accuracy: 0.9954 - val_loss: 0.2158 - val_accuracy: 0.9429\n",
      "Epoch 13/20\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.0213 - accuracy: 0.9963 - val_loss: 0.2031 - val_accuracy: 0.9422\n",
      "Epoch 14/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0199 - accuracy: 0.9978 - val_loss: 0.2166 - val_accuracy: 0.9456\n",
      "Epoch 15/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 0.2149 - val_accuracy: 0.9401\n",
      "Epoch 16/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.2204 - val_accuracy: 0.9456\n",
      "Epoch 17/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0130 - accuracy: 0.9983 - val_loss: 0.2310 - val_accuracy: 0.9388\n",
      "Epoch 18/20\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 0.2271 - val_accuracy: 0.9422\n",
      "Evaluation:\n",
      "108/108 [==============================] - 4s 33ms/step - loss: 0.2327 - accuracy: 0.9408\n",
      "-----------------------------------------\n",
      "########################################################\n",
      "ResNet50 entrenamiento con TF y FT 3 bloques- Iteración 5 de 5\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "#Ejecutamos los experimentos\n",
    "\n",
    "#res11,res12,evaluations11,evaluations12 = run_experiment(\"RSM_BAJ entrenamiento\",\"RSM_BAJ\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 1,iterations = 5)\n",
    "\n",
    "#res11,res12,evaluations11,evaluations12  = run_experiment(\"VGG-16 entrenamiento con TF y FT 1 bloques\",\"VGG16\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 1,iterations = 5)\n",
    "#res21,res22,evaluations21,evaluations22 = run_experiment(\"VGG-16 entrenamiento con TF y FT 2 bloques\",\"VGG16\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 2,iterations = 5)\n",
    "\n",
    "#res11,res12,evaluations11,evaluations12  = run_experiment(\"IV3 entrenamiento con TF y FT 1 bloques\",\"IV3\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 1,iterations = 5)\n",
    "#res21,res22,evaluations21,evaluations22 = run_experiment(\"IV3 entrenamiento con TF y FT 2 bloques\",\"IV3\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 2,iterations = 5)\n",
    "\n",
    "#res11,res12,evaluations11,evaluations12  = run_experiment(\"ResNet50 entrenamiento con TF y FT 1 bloques\",\"ResNet50\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 1,iterations = 5)\n",
    "#res21,res22,evaluations21,evaluations22  = run_experiment(\"ResNet50 entrenamiento con TF y FT 2 bloques\",\"ResNet50\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 2,iterations = 5)\n",
    "#res31,res32,evaluations31,evaluations32  = run_experiment(\"ResNet50 entrenamiento con TF y FT 3 bloques\",\"ResNet50\",EPOCHS,LEARNING_RATE,True,trainable_blocks = 3,iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_layers_become_trainables(model):\n",
    "    layers = model.layers[0:-1]\n",
    "    for layer in layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "\n",
    "def run_experiment(title,nn_base_arch,epoch,lr,fine_tuning,trainable_blocks = 1,iterations = ITERATIONS_PER_EXP):\n",
    "    \n",
    "    result = []\n",
    "    evaluations = []\n",
    "    \n",
    "    result_post_ft=[]\n",
    "    evaluations_post_ft=[]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print(\"---Transfer learning phase -----\")\n",
    "        #Transfer learning\n",
    "        if nn_base_arch == \"VGG16\":\n",
    "            h,e,model = run_VGG_train(epoch,lr,16,trainable_blocks)\n",
    "        elif nn_base_arch == \"VGG19\":\n",
    "            h,e,model = run_VGG_train(epoch,lr,19,trainable_blocks)\n",
    "        elif nn_base_arch == \"ResNet50\":\n",
    "            h,e,model = run_ResNet_train(epoch,lr,50,trainable_blocks)\n",
    "        elif nn_base_arch == \"IV3\":\n",
    "            h,e,model = run_IV3_train(epoch,lr,0,trainable_blocks)\n",
    "\n",
    "        result.append(h)\n",
    "        evaluations.append(e)\n",
    "        print(model)\n",
    "        if fine_tuning:\n",
    "            print(\"---Finetuning phase -----\")\n",
    "            print(\"Learning Rate ->\"+str(lr/10))\n",
    "            all_layers_become_trainables(model)\n",
    "            history,evaluation,model = check_train(model,lr/10,epoch,nn_base_arch,i,trainable_blocks)\n",
    "        \n",
    "            result_post_ft.append(history)\n",
    "            evaluations_post_ft.append(evaluation)\n",
    "        \n",
    "        \n",
    "        print(\"########################################################\")\n",
    "        print(title + \"- Iteración \"+str(i+1) +\" de \"+ str(iterations))\n",
    "        print(\"########################################################\")\n",
    "        \n",
    "    return result,result_post_ft,evaluations,evaluations_post_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ResNet_train(epoch,lr,net,trainable_blocks=1):\n",
    "    if net == 50:\n",
    "        nn_base_arch = 'ResNet50'\n",
    "        nn = select_network(nn_base_arch)\n",
    "        model = build(nn)\n",
    "        \n",
    "    def prepare_cnn_for_transfer_learning(model,net,trainable_blocks):\n",
    "        if net == 50:\n",
    "            if trainable_blocks == -1:\n",
    "                for layer in model.layers[0].layers[0:-1]:   # Se congelan el ultimo módulos dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            elif trainable_blocks == 1:\n",
    "                for layer in model.layers[0].layers[0:164]:   # Se congelan el ultimo módulos dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            elif trainable_blocks == 2:\n",
    "                for layer in model.layers[0].layers[0:155]:   # Se congelan los dos últimos bloques dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            elif trainable_blocks == 3:\n",
    "                for layer in model.layers[0].layers[0:142]:   # Se congelan los tres últimos bloques dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                raise(\"Solo se admite como parametro 1,2 o 3\")\n",
    "                \n",
    "            print(\"Estas entrenando ResNet50 con \"+str(net))\n",
    "        return model\n",
    "                    \n",
    "    model = prepare_cnn_for_transfer_learning(model,net,trainable_blocks)\n",
    "    history,evaluation,model = general_train(model,lr,epoch)\n",
    "    \n",
    "    return history,evaluation,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_IV3_train(epoch,lr,net,trainable_blocks=1):\n",
    "    if net == 0:\n",
    "        nn_base_arch = 'IV3'\n",
    "        nn = select_network(nn_base_arch)\n",
    "        model = build(nn)\n",
    "        \n",
    "    def prepare_cnn_for_transfer_learning(model,net,trainable_blocks):\n",
    "        if net == 0:\n",
    "            if trainable_blocks == -1:\n",
    "                for layer in model.layers[0].layers[0:-1]:   # Se congelan el ultimo módulos dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            elif trainable_blocks == 1:\n",
    "                for layer in model.layers[0].layers[0:197]:   # Se congelan el ultimo módulos dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                raise(\"Solo se admite como parametro 1 y -1\")\n",
    "                \n",
    "            print(\"Estas entrenando IV3 con \"+str(trainable_blocks))\n",
    "        return model\n",
    "                    \n",
    "    model = prepare_cnn_for_transfer_learning(model,net,trainable_blocks)\n",
    "    history,evaluation,model = general_train(model,lr,epoch)\n",
    "    \n",
    "    return history,evaluation,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_train(model,lr,epoch,nn_base_arch,i,trainable_blocks):\n",
    "    earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 5, mode = 'min')\n",
    "    cpoint = tf.keras.callbacks.ModelCheckpoint(\"../TFG/Modelos/\"+str(nn_base_arch)+\"_\"+str(i)+\"_\"+str(trainable_blocks)+\".h5\", monitor=\"val_loss\", mode=\"min\",\n",
    "                                                save_best_only=True,verbose=0)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr,amsgrad=True)  \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,validation_data=(x_validation, y_validation),epochs=epoch,callbacks=[earlyStopping,cpoint],batch_size = BATCH_SIZE)\n",
    "    print(\"Evaluation:\")\n",
    "    evaluation = model.evaluate(x_test, y_test)\n",
    "    print(\"-----------------------------------------\")\n",
    "    return history,evaluation,model\n",
    "\n",
    "def general_train(model,lr,epoch):\n",
    "    earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 5, mode = 'min')\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr,amsgrad=True)  \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,validation_data=(x_validation, y_validation),epochs=epoch,callbacks=[earlyStopping],batch_size = BATCH_SIZE)\n",
    "    print(\"Evaluation:\")\n",
    "    evaluation = model.evaluate(x_test, y_test)\n",
    "    print(\"-----------------------------------------\")\n",
    "    return history,evaluation,model\n",
    "    \n",
    "def run_VGG_train(epoch,lr,net,trainable_blocks=1):\n",
    "    if net == 16:\n",
    "        nn_base_arch = 'VGG16'\n",
    "        nn = select_network(nn_base_arch)\n",
    "        model = build(nn)\n",
    "    if net == 19:\n",
    "        nn_base_arch = 'VGG19'\n",
    "        nn = select_network(nn_base_arch)\n",
    "        model = build(nn)\n",
    "        \n",
    "    def prepare_cnn_for_transfer_learning(model,net,trainable_blocks):\n",
    "        if net == 16:\n",
    "            if trainable_blocks == 1:\n",
    "                for layer in model.layers[0].layers[0:15]:   # Se congelan el ultimo módulos dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            elif trainable_blocks == 2:\n",
    "                for layer in model.layers[0].layers[0:11]:   # Se congelan los dos últimos bloques dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                raise(\"Solo se admite como parametro 1 o 2\")\n",
    "        \n",
    "        if net == 19:\n",
    "            if trainable_blocks == 1:\n",
    "                for layer in model.layers[0].layers[0:17]:   # Se congelan el ultimo módulos dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            elif trainable_blocks == 2:\n",
    "                for layer in model.layers[0].layers[0:12]:   # Se congelan los dos últimos bloques dejando libres los superiores\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                print(\"Solo se admite como parametro 1 o 2\")\n",
    "                \n",
    "        return model\n",
    "                    \n",
    "    model = prepare_cnn_for_transfer_learning(model,net,trainable_blocks)\n",
    "    history,evaluation,model = general_train(model,lr,epoch)\n",
    "    \n",
    "    return history,evaluation,model\n",
    "\n",
    "\n",
    "def run_train(nn_base_arch,epochs,checkpoint,dense = False):\n",
    "    nn = select_network(nn_base_arch)\n",
    "    \n",
    "    if dense == True :\n",
    "        model = build_dense(nn)\n",
    "    else:\n",
    "        model = build(nn)\n",
    "        \n",
    "    cpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=0)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy','mse'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,epochs=EPOCHS,callbacks=[cpoint],batch_size = BATCH_SIZE,verbose=0)\n",
    "      \n",
    "    evaluation = model.evaluate(x_test, y_test)\n",
    "        \n",
    "    return history,evaluation\n",
    "\n",
    "def run_train_w_model(nn_base_arch,epochs,checkpoint,dense = False):\n",
    "    nn = select_network(nn_base_arch)\n",
    "    \n",
    "    if dense == True :\n",
    "        model = build_dense(nn)\n",
    "    else:\n",
    "        model = build(nn)\n",
    "        \n",
    "    cpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=0)\n",
    "    earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 5, mode = 'min') \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy','mse'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train,validation_data=(x_validation, y_validation),epochs=EPOCHS,callbacks=[earlyStopping],batch_size = BATCH_SIZE,verbose=1)\n",
    "    \n",
    "    print(len(x_test))\n",
    "    \n",
    "    evaluation = model.evaluate(x_test, y_test)\n",
    "        \n",
    "    return history,evaluation,model\n",
    "\n",
    "def re_train(model,epocas):\n",
    "    #checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=0)\n",
    "    earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 5, mode = 'min') \n",
    "    history = model.fit(x_train, y_train,validation_data=(x_validation, y_validation),epochs=EPOCHS,callbacks=[earlyStopping],batch_size = BATCH_SIZE,verbose=2)\n",
    "    evaluation = model.evaluate(x_test, y_test)\n",
    "    return history,evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos marcos de datos para analizar los resultados de evaluar los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50-tf    0.175853\n",
      "ResNet50-ft    0.942316\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "precision1 = []\n",
    "precision2 = []\n",
    "precision3 = []\n",
    "precision4 = []\n",
    "precision5 = []\n",
    "precision6 = []\n",
    "precision7 = []\n",
    "\n",
    "for e in evaluations31:\n",
    "    element = e[1]\n",
    "    precision1.append(element)\n",
    "\n",
    "for e in evaluations32:\n",
    "    element = e[1]\n",
    "    precision2.append(element)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "d = {'ResNet50-tf': precision1,'ResNet50-ft': precision2}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "print(df.mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    2.000000\n",
      "VGG16-tf      0.956372\n",
      "VGG16-ft      0.958880\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/antgarnie/Escritorio/TFG/Backups/VGG16_1\")\n",
    "print(df.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     2.00000\n",
      "ResNet50-tf    0.17457\n",
      "ResNet50-ft    0.95818\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"/home/antgarnie/Escritorio/TFG/Backups/VGG16_2\")\n",
    "print(df1.mean())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vgg16vs19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
