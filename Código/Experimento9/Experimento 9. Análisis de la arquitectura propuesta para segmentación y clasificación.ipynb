{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsBFD7icF6Xc"
   },
   "source": [
    "# Experimento 4 : Análisis de arquitecturas clásicas.\n",
    "\n",
    "En este experimento estudiaremos el comportamiento de las arquitecturas de redes neuronales más relevante a lo largo de la historia de las CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "print(len(gpus))\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxC7JJwlFuvk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkqu4FPPGQgV"
   },
   "source": [
    "## Definición de rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZazLFjjGZVf"
   },
   "outputs": [],
   "source": [
    "#Rutas de los datos.\n",
    " \n",
    "data_dir = os.path.dirname(os.path.realpath(\"../TFG/Datos/HAM10000_metadata.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "csv_path = os.path.realpath(data_dir + \"/HAM10000_metadata.csv\")\n",
    "\n",
    "#Variables globales\n",
    "\n",
    "altura = 128\n",
    "longitud = 128\n",
    "clases = 7\n",
    "\n",
    "\n",
    "print(data_dir)\n",
    "\n",
    "print(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_mascara_binaria = os.path.dirname(os.path.realpath(\"../TFG/DatosMascaraBinaria2/HAM10000_segmentations/...\"))\n",
    "data_dir_mascara_superpuesta = os.path.dirname(os.path.realpath(\"../TFG/DatosMascaraSuperpuesta/...\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD9w48fEGfkF"
   },
   "source": [
    "## Creación del marco de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "pf0IBVhhGehu",
    "outputId": "af59739a-413e-4a7d-c5ac-b775ab675e5d"
   },
   "outputs": [],
   "source": [
    "def combineData(data_dir):\n",
    "    all_image_path = glob(os.path.join(data_dir, '*', '*'))\n",
    "    imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "    return imageid_path_dict\n",
    "\n",
    "def combineData_1(data_dir):\n",
    "    all_image_path = glob(os.path.join(data_dir, '*'))\n",
    "    imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "    return imageid_path_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Inicializando el dataFrame\n",
    "\n",
    "dataFrame=pd.read_csv(csv_path)\n",
    "\n",
    "#Mezclando carpetas.\n",
    "\n",
    "data_dict = combineData(data_dir)\n",
    "data_dict_mask = combineData_1(data_dir_mascara_binaria)\n",
    "\n",
    "def rename_keys(d, keys):\n",
    "    return dict([(keys.get(k,k), v) for k, v in d.items()])\n",
    "\n",
    "keys_values_transformer = {}\n",
    "for element in data_dict_mask.keys():\n",
    "    element_trans = element.replace(\"_segmentation\",\"\")\n",
    "    keys_values_transformer[element]  = element_trans\n",
    "    \n",
    "\n",
    "\n",
    "data_dict_mask = rename_keys(data_dict_mask, keys_values_transformer)\n",
    "\n",
    "\n",
    "data_dict_rgb_mask = combineData(data_dir_mascara_superpuesta)\n",
    "\n",
    "# Inicializando diccionario de categorías\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "#Añadiendo columnas al dataFrame para que sea más legible.\n",
    "\n",
    "dataFrame['path'] = dataFrame['image_id'].map(data_dict.get)\n",
    "dataFrame['mask_path'] = dataFrame['image_id'].map(data_dict_mask.get)\n",
    "dataFrame['rgb_mask_path'] = dataFrame['image_id'].map(data_dict_rgb_mask.get)\n",
    "dataFrame['cell_type'] = dataFrame['dx'].map(lesion_type_dict.get) \n",
    "dataFrame['cell_type_idx'] = pd.Categorical(dataFrame['cell_type']).codes\n",
    "\n",
    "dataFrame = dataFrame.drop('dx', 1)\n",
    "dataFrame = dataFrame.drop('dx_type', 1)\n",
    "dataFrame = dataFrame.drop('age', 1)\n",
    "dataFrame = dataFrame.drop('sex', 1)\n",
    "dataFrame = dataFrame.drop('localization', 1)\n",
    "\n",
    "dataFrame.head()\n",
    "\n",
    "34771273B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se procede a crear un método que permita balancear la carga de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NO6Snfw-KYe4"
   },
   "outputs": [],
   "source": [
    "def balanced_dataset(df):\n",
    "    df_balanced = pd.DataFrame()\n",
    "    #df = pd.DataFrame()\n",
    "    \n",
    "    for cat in df['cell_type_idx'].unique():\n",
    "        temp = resample(df[df['cell_type_idx'] == cat], \n",
    "                        replace=True,     # sample with replacement\n",
    "                        n_samples=2500,   # to match majority class\n",
    "                        random_state=123) # reproducible results\n",
    "\n",
    "        # Combine majority class with upsampled minority class\n",
    "        df_balanced = pd.concat([df_balanced, temp])\n",
    " \n",
    "    df_balanced['cell_type'].value_counts()\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "def load_img_data(size, df, balanced=False):\n",
    "    \"\"\"\n",
    "        ..\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    img_h, img_w = size, size\n",
    "    imgs = []\n",
    "    \n",
    "    if balanced:\n",
    "        df = balanced_dataset(df)\n",
    "    \n",
    "    image_paths = list(df['path'])\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        #img = np.asarray(Image.open(image_paths[i]).resize((size,size)))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    #imgs = imgs.astype(np.float32) / 255.\n",
    "    \n",
    "    return imgs, df['cell_type_idx'].values\n",
    "\n",
    "def load_img_data_segmentation(size, df, balanced=False):\n",
    "    \"\"\"\n",
    "        ..\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    img_h, img_w = size, size\n",
    "    imgs = []\n",
    "    imgs_segmented = []\n",
    "    \n",
    "    if balanced:\n",
    "        df = balanced_dataset(df)\n",
    "    \n",
    "    image_paths = list(df['path'])\n",
    "    image_paths_1 = list(df['mask_path'])\n",
    "\n",
    "    imgs = preproces_image(image_paths,img_h, img_w)\n",
    "    imgs_seg = preproces_image(image_paths_1,img_h, img_w)\n",
    "\n",
    "    #imgs = imgs.astype(np.float32) / 255.\n",
    "    \n",
    "    return imgs,imgs_seg, df['cell_type_idx'].values\n",
    "\n",
    "\n",
    "def preproces_image(image_paths,img_h, img_w):\n",
    "    imgs = []\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        #img = np.asarray(Image.open(image_paths[i]).resize((size,size)))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "    print(imgs.shape)\n",
    "    return imgs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, seg_imgs, values = load_img_data_segmentation(128, dataFrame, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_general_data(imgs, seg_imgs, values):\n",
    "    \n",
    "    x_train_img,x_test_img,y_train_seg,y_test_seg,y_train_clas,y_test_clas = train_test_split(imgs, seg_imgs,values, test_size=0.40,random_state=123)\n",
    "\n",
    "       \n",
    "    train_data = [ x_train_img , y_train_seg,y_train_clas]\n",
    "    test_data = [ x_test_img , y_test_seg, y_test_clas ]\n",
    "    \n",
    "    x_test_img,x_val_img,y_test_seg,y_val_seg,y_test_clas,y_val_clas = train_test_split(test_data[0], test_data[1],test_data[2], test_size=0.60,random_state=123)\n",
    "\n",
    "    \n",
    "    \n",
    "    train_data = [x_train_img , y_train_seg,y_train_clas]\n",
    "    val_data   = [x_val_img , y_val_seg, y_val_clas]\n",
    "    test_data  = [x_test_img , y_test_seg,y_test_clas]\n",
    "    \n",
    "    print(\"Work DONE\")\n",
    "    \n",
    "    return train_data,val_data,test_data\n",
    "\n",
    "train_data,val_data,test_data = load_general_data(imgs, seg_imgs, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos y creamos los casos a experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_general_data():\n",
    "    \n",
    "    imgs, target = load_img_data(altura, dataFrame, balanced=True)\n",
    "    \n",
    "    x_train, x_transferLearning, y_train, y_transferLearning = train_test_split(imgs, target, test_size=0.60,random_state=123)\n",
    "       \n",
    "    source_data = [ x_transferLearning , y_transferLearning ]\n",
    "    target_data = [ x_train , y_train ]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(target_data[0], target_data[1], test_size=0.70,random_state=123)\n",
    "    \n",
    "    train_data = [x_train,y_train]\n",
    "    test_data = [x_test,y_test]\n",
    "    \n",
    "    return source_data,train_data,test_data\n",
    "\n",
    "\n",
    "def get_data_for_ex(source_data,train_data,test_data):\n",
    "    \n",
    "    x_train = source_data[0]\n",
    "    y_train = source_data[1]\n",
    "    \n",
    "    x_retrain = train_data[0]\n",
    "    y_retrain = train_data[1]\n",
    "    \n",
    "    percent = math.floor(len(test_data[0])/100*30)\n",
    "       \n",
    "    x_validation = test_data[0][0:percent]\n",
    "    y_validation = test_data[1][0:percent]\n",
    "    \n",
    "    \n",
    "    x_test = test_data[0][percent:-1]\n",
    "    y_test = test_data[1][percent:-1]\n",
    "    \n",
    "    return x_train,x_retrain,x_test,x_validation,y_train,y_retrain,y_test,y_validation\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "# Definimos 7 experimentos cada uno con un optimizador distingo y definimos el número de iteraciones          #\n",
    "###############################################################################################################\n",
    "\n",
    "ITERATIONS_PER_EXP = 5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE=0.0001\n",
    "\n",
    "\n",
    "def set_hiper_to_exp(BATCH_SIZE,EPOCHS,LEARNING_RATE):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE,amsgrad=True)  \n",
    "    return BATCH_SIZE,EPOCHS,opt\n",
    "\n",
    "BATCH_SIZE,EPOCHS,opt = set_hiper_to_exp(BATCH_SIZE,EPOCHS,LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasifier(x,out_name):\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(7,activation='softmax',name=out_name)(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "    x = conv_block(image,32,kernel_size=(3,3),with_bn=with_bn)\n",
    "    x = conv_block(x,32,kernel_size=(3,3),with_bn=with_bn)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "    \n",
    "    \n",
    "    x = conv_block(x,64,kernel_size=(3,3),with_bn=with_bn)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "    \n",
    "def encoder(image):\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(image)\n",
    "    #conv1 = tf.keras.layers.PReLU()(conv1)\n",
    "    #conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    #conv1  = tf.keras.layers.PReLU()(conv1)\n",
    "    #conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n",
    "    \n",
    "    pool1 = tf.keras.layers.MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    #conv2 = tf.keras.layers.PReLU()(conv2)\n",
    "    #conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    #conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    return pool2,conv2,conv1\n",
    "\n",
    "def decoder(pool2,conv2,conv1):\n",
    "    \n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='elu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n",
    "    #conv3 = tf.keras.layers.BatchNormalization()(conv3)    \n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n",
    "\n",
    "    up1 = tf.keras.layers.concatenate([tf.keras.layers.UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "    conv4 = tf.keras.layers.Dropout(0.2)(conv4)\n",
    "    #conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up2 = tf.keras.layers.concatenate([tf.keras.layers.UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "    conv5 = tf.keras.layers.Dropout(0.2)(conv5)\n",
    "    #conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    out = tf.keras.layers.Conv2D( 1, (1, 1) , padding='same',name=\"decoder_output\")(conv5)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def clasifier_v2(x,out_name):\n",
    "    #x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(256)(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(7,activation='softmax',name=out_name)(x)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "def encoder_v2(image):\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(image)\n",
    "    #conv1 = tf.keras.layers.PReLU()(conv1)\n",
    "    #conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    #conv1  = tf.keras.layers.PReLU()(conv1)\n",
    "    #conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n",
    "    \n",
    "    pool1 = tf.keras.layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    #conv2 = tf.keras.layers.PReLU()(conv2)\n",
    "    #conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = tf.keras.layers.Dropout(0.2)(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n",
    "    #conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    return conv3,conv2,conv1\n",
    "\n",
    "def decoder_v2(conv3,conv2,conv1):\n",
    "    \n",
    "    \n",
    "\n",
    "    up1 = tf.keras.layers.concatenate([tf.keras.layers.UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = tf.keras.layers.Conv2D(64, (3, 3), activation='elu', padding='same')(up1)\n",
    "    conv4 = tf.keras.layers.Dropout(0.2)(conv4)\n",
    "    conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
    "    conv4 = tf.keras.layers.Conv2D(64, (3, 3), activation='elu', padding='same')(conv4)\n",
    "\n",
    "    up2 = tf.keras.layers.concatenate([tf.keras.layers.UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = tf.keras.layers.Conv2D(32, (3, 3), activation='elu', padding='same')(up2)\n",
    "    conv5 = tf.keras.layers.Dropout(0.2)(conv5)\n",
    "    #conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(32, (3, 3), activation='elu', padding='same')(conv5)\n",
    "    \n",
    "    out = tf.keras.layers.Conv2D( 1, (1, 1) , padding='same',name=\"decoder_output\")(conv5)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_dec_v1(input_shape=(128, 128, 3)):\n",
    "    image = tf.keras.layers.Input(shape=input_shape)\n",
    "    conv3,conv2,conv1 = encoder(image)\n",
    "    out1 = decoder(conv3,conv2,conv1)\n",
    "    out = clasifier(conv3,\"softmax_output\")\n",
    "    model = tf.keras.models.Model(image,outputs=[out,out1])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def enc_dec_v2(input_shape=(128, 128, 3)):\n",
    "    image = tf.keras.layers.Input(shape=input_shape)\n",
    "    conv3,conv2,conv1 = encoder_v2(image)\n",
    "    out1,conv4,conv5 = decoder_v2(conv3,conv2,conv1)\n",
    "    out,conv4,conv5 = clasifier_v2(conv3,conv4,conv5,\"softmax_output\")\n",
    "    model = tf.keras.models.Model(image,outputs=[out,out1])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def clasiffier(input_shape=(128, 128, 3)):\n",
    "    image = tf.keras.layers.Input(shape=input_shape)\n",
    "    conv3,conv2,conv1 = encoder(image)\n",
    "    out = clasifier(conv3,\"softmax_output\")\n",
    "    \n",
    "    model = tf.keras.models.Model(image,outputs=[out])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = clasiffier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(nn):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(nn)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(7,activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "def conv_block(x,filters,kernel_size = (3,3),strides = (1,1),with_bn=False):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,kernel_size=kernel_size,strides=strides)(x)\n",
    "    x  = tf.keras.layers.PReLU()(x)\n",
    "    if with_bn: \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def full_build_cnn_soco_v4(clases = 7,with_bn = True, with_dropout=False,stn=0,input_shape=(128, 128, 3)):\n",
    "    image = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = conv_block(image,32,kernel_size=(3,3),with_bn=with_bn)\n",
    "    x = conv_block(x,32,kernel_size=(3,3),with_bn=with_bn)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "    \n",
    "    \n",
    "    x = conv_block(x,64,kernel_size=(3,3),with_bn=with_bn)\n",
    "    x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "    \n",
    "      \n",
    "    model = tf.keras.models.Model(inputs=image, outputs=x)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = full_build_cnn_soco_v4()\n",
    "nn = build(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clasiffier()\n",
    "\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10,\n",
    "                                                         mode = 'min')\n",
    "\n",
    "#cb_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1,\n",
    "                                                     #patience=4, min_delta=1e-3, \n",
    "                                                     #cooldown=0, min_lr=0.000001)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001,amsgrad=True)        \n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train_clas,\n",
    "                     validation_data= (x_val_img,y_val_clas),\n",
    "                     epochs=60,\n",
    "                     callbacks = [earlyStopping,cb_reduce_lr],\n",
    "                     batch_size=16,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[0]\n",
    "y_train_seg = train_data[1]\n",
    "y_train_clas = train_data[2]\n",
    "\n",
    "x_val_img = val_data[0]\n",
    "y_val_seg = val_data[1]\n",
    "y_val_clas = val_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train_seg.shape)\n",
    "print(y_train_clas.shape)\n",
    "print(x_val_img.shape)\n",
    "print(y_val_seg.shape)\n",
    "print(y_val_clas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(iteraciones):\n",
    "    evaluations = []\n",
    "    for i in range(iteraciones):\n",
    "        \n",
    "        model = enc_dec_v2()\n",
    "        \n",
    "        checkpoint =\"../TFG/Modelos/prop_500_light_\"+str(i)+\".h5\"\n",
    "        \n",
    "        cpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint, monitor=\"val_loss\",\n",
    "                                                    mode=\"min\", save_best_only=True, verbose=0)\n",
    "        \n",
    "        earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5,\n",
    "                                                         mode = 'min')\n",
    "        \n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001,amsgrad=True)\n",
    "        \n",
    "        losses = {\n",
    "            \"decoder_output\": \"binary_crossentropy\",\n",
    "            \"softmax_output\": \"sparse_categorical_crossentropy\",\n",
    "        }\n",
    "\n",
    "        lossWeights = {\n",
    "            \"decoder_output\": 1.0,\n",
    "            \"softmax_output\": 1.0\n",
    "        }\n",
    "    \n",
    "        cb_reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, verbose=1,\n",
    "                                                     patience=2, min_delta=1e-3, \n",
    "                                                     cooldown=0, min_lr=0.00001)\n",
    "        \n",
    "        model.compile(optimizer=opt,\n",
    "              loss=losses,\n",
    "              loss_weights=lossWeights,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        history = model.fit(x_train,[y_train_clas,y_train_seg],\n",
    "                     validation_data= (x_val_img,[y_val_clas,y_val_seg]),\n",
    "                     epochs=60,\n",
    "                     callbacks = [cpoint,earlyStopping,cb_reduce_lr],\n",
    "                     batch_size=16,verbose=2)\n",
    "        \n",
    "        evaluation = history.model.evaluate(test_data[0],[test_data[2],test_data[1]])\n",
    "        evaluations.append(evaluation)\n",
    "    \n",
    "    return evaluations\n",
    "    \n",
    "evaluations = train_model(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.evaluate(test_data[0],test_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stats\n",
    "\n",
    "classifiers_acc = []\n",
    "decoders_acc = []\n",
    "\n",
    "for [gloss,closs,dloss,cacc,dacc] in evaluations:\n",
    "    print(str(cacc)+\" \"+str(dacc))\n",
    "    classifiers_acc.append(cacc)\n",
    "    decoders_acc.append(dacc)\n",
    "\n",
    "print(\"-------------------------\")\n",
    "print(stats.mean(classifiers_acc))\n",
    "print(stats.mean(decoders_acc))\n",
    "print(\"-------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../TFG/Modelos/prop\"+str(0)+\".h5\")\n",
    "\n",
    "model.evaluate(test_data[0],[test_data[2],test_data[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=343\n",
    "  \n",
    "\n",
    "    \n",
    "def print_prediction(i):\n",
    "    pixels = np.array(x_test[i])\n",
    "    image = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "    gt = np.array(y_test_seg[i])\n",
    "\n",
    "    i,m = model.model.predict(x_test[i][None,:,:,:])\n",
    "    prediction = m[0,:,:,:]>=0.5\n",
    "\n",
    "    \n",
    "    display_list = [image,gt,prediction]\n",
    "    \n",
    "    title= [\"Input Image\",\"Ground Truth\",\"Predicted Image\"]\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1,3,i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()  \n",
    "    \n",
    "\n",
    "for i in range(0,10):\n",
    "    print_prediction(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m[0,:,:,:]>= 0.5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_test_seg[3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = np.array(x_test[3])\n",
    "image = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData(data_dir):\n",
    "    all_image_path = glob(os.path.join(data_dir, '*', '*'))\n",
    "    imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "    return imageid_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_thresh = (test_preds >= 0.5).astype(np.uint8)\n",
    "test_img = preds_test_thresh[5, :, :, 0]\n",
    "plt.imshow(test_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.model.predict(x_test[0][None,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_img = 8\n",
    "pixels = np.array(x_test[0])\n",
    "image = cv2.cvtColor(pixels, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "preds_test_thresh = (test_preds[0] >= 0.4).astype(np.uint8)\n",
    "pixels = np.array(preds_test_thresh)\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = np.array(y_test[0])\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "pixels = np.array(test_preds[0])\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vgg16vs19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
