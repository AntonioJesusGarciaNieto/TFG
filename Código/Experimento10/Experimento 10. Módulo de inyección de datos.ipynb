{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsBFD7icF6Xc"
   },
   "source": [
    "# Experimento 10 : Módulo de inyección de datos.\n",
    "\n",
    "En este experimento se pretende crear una red neuronal basada en los datos contextuales adheridos al conjunto de datos objeto de este proyecto.\n",
    "\n",
    "El análisis de imágenes es una buena herramienta, pero trabajar con datos contextuales puede aumentar la precisión del diagnóstico.\n",
    "\n",
    "En este caso es importante evaluar el rendimiento del modelo neuronal, esto es decisivo de cara a decidir si proseguir o no con el problema. Como ya se ha constatado en  experimentos anteriores uno de los factores determinantes para que un ensamblaje de modelos funcione es que ambos modelos tienen una precisión similar.\n",
    "\n",
    "Basado en lo anterior en este estudio se plantea la siguiente hipótesis:\n",
    "- Una red neuronal sencilla basada en información contextual puede conseguir un desempeño óptimo y posteriormente usarse en un ensamblaje de modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxC7JJwlFuvk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkqu4FPPGQgV"
   },
   "source": [
    "## Definición de rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZazLFjjGZVf"
   },
   "outputs": [],
   "source": [
    "#Rutas de los datos.\n",
    " \n",
    "data_dir = os.path.dirname(os.path.realpath(\"../TFG/Datos/HAM10000_metadata.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "csv_path = os.path.realpath(data_dir + \"/HAM10000_metadata.csv\")\n",
    "\n",
    "#Variables globales\n",
    "\n",
    "clases = 7\n",
    "\n",
    "\n",
    "print(data_dir)\n",
    "\n",
    "print(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD9w48fEGfkF"
   },
   "source": [
    "## Creación del marco de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "pf0IBVhhGehu",
    "outputId": "af59739a-413e-4a7d-c5ac-b775ab675e5d"
   },
   "outputs": [],
   "source": [
    "def combineData(data_dir):\n",
    "    all_image_path = glob(os.path.join(data_dir, '*', '*'))\n",
    "    imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "    return imageid_path_dict\n",
    "\n",
    "#Inicializando el dataFrame\n",
    "data_dir_mascara_binaria = os.path.dirname(os.path.realpath(\"../TFG/DatosMascaraBinaria/...\"))\n",
    "data_dict_mask = combineData(data_dir_mascara_binaria)\n",
    "\n",
    "dataFrame=pd.read_csv(csv_path)\n",
    "\n",
    "#Mezclando carpetas.\n",
    "\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "\n",
    "# Inicializando diccionario de categorías\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "#Añadiendo columnas al dataFrame para que sea más legible.\n",
    "\n",
    "dataFrame['path'] = dataFrame['image_id'].map(imageid_path_dict.get)\n",
    "dataFrame['mask_path'] = dataFrame['image_id'].map(data_dict_mask.get)\n",
    "dataFrame['cell_type'] = dataFrame['dx'].map(lesion_type_dict.get)\n",
    "\n",
    "dataFrame['cell_type_idx'] = pd.Categorical(dataFrame['cell_type']).codes\n",
    "dataFrame.head()\n",
    "df = dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMissingParams(data,color=\"blue\",val=False):\n",
    "    plt.figure(figsize = (13,5))\n",
    "    if val:\n",
    "        plt.bar(data.columns, data.isnull().sum(), color = color)\n",
    "    else:\n",
    "        plt.bar(data.columns, data.isna().sum(),color=color)\n",
    "    plt.xlabel(\"Nombre de las columnas\")\n",
    "    plt.ylabel(\"Número celdas vacías\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMissingParams(dataFrame,color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_not_used_elements(dataFrame):\n",
    "    dataFrame.drop(\"lesion_id\", axis = 1,inplace = True)\n",
    "    dataFrame.drop(\"image_id\", axis = 1,inplace = True)\n",
    "    dataFrame.drop(\"dx\", axis = 1,inplace = True)\n",
    "    dataFrame.drop(\"path\", axis = 1,inplace = True)\n",
    "    dataFrame.drop(\"mask_path\", axis = 1,inplace = True)\n",
    "    dataFrame.drop(\"cell_type\", axis = 1,inplace = True)\n",
    "\n",
    "def map_values(dataFrame,element,value_map):\n",
    "    dataFrame[element] = dataFrame[element].map(value_map)\n",
    "\n",
    "def map_age(dataFrame):\n",
    "    dataFrame.loc[ dataFrame['age'] <= 16, 'age'] = 0\n",
    "    dataFrame.loc[(dataFrame['age'] > 16) & (dataFrame['age'] <= 32), 'age'] = 1\n",
    "    dataFrame.loc[(dataFrame['age'] > 32) & (dataFrame['age'] <= 48), 'age'] = 2\n",
    "    dataFrame.loc[(dataFrame['age'] > 48) & (dataFrame['age'] <= 64), 'age'] = 3\n",
    "    dataFrame.loc[ dataFrame['age'] > 64, 'age'] = 4\n",
    "\n",
    "def fill_all_empties_values(dataFrame):\n",
    "    \n",
    "    # Calculamos la media de las edades y sustituimos los valores vacios por el resultado.\n",
    "    dataFrame[\"age\"] = dataFrame[\"age\"].fillna(dataFrame[\"age\"].mean())\n",
    "    \n",
    "    #   Sustituimos los valores nulos \"female\". Esto es debido a que existen\n",
    "    # menos mujeres que hombres y pretendemos balancear el conjunto de datos.\n",
    "    dataFrame['sex'].fillna(\"female\",inplace=True)\n",
    "    \n",
    "    return dataFrame\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def map_all_values(dataFrame): \n",
    "    lesion_evaluation_type_map = {\"histo\": 1, \"follow_up\": 2, \"consensus\": 3, \"confocal\": 4}\n",
    "    localization_map = {\"acral\": 0,\"back\": 1,\"lower extremity\" : 2,\"trunk\": 3,\"upper extremity\":4,\"abdomen\":5,\"face\":6,\"chest\":7,\"foot\":8,\"unknown\":9,\"neck\":10,\"scalp\":11,\"hand\":12,\"ear\":13,\"genital\":14}\n",
    "    gender_mapping = {\"male\": 1, \"female\":0}    \n",
    "    \n",
    "    map_values(dataFrame,'localization',localization_map)\n",
    "    map_values(dataFrame,'dx_type',lesion_evaluation_type_map)\n",
    "    map_values(dataFrame,'sex',gender_mapping)\n",
    "    map_age(dataFrame)\n",
    "\n",
    "    \n",
    "def data_inyection_module(dataFrame):\n",
    "    dataFrame = fill_all_empties_values(dataFrame)\n",
    "    map_all_values(dataFrame)\n",
    "    drop_not_used_elements(dataFrame)\n",
    "    print(dataFrame.head())\n",
    "    data = shuffle(dataFrame, random_state=123)\n",
    "    data.fillna(0,inplace=True)\n",
    "    df_balanced = pd.DataFrame()\n",
    "    for cat in df['cell_type_idx'].unique():\n",
    "        temp = resample(df[df['cell_type_idx'] == cat],\n",
    "                        replace=True,     # sample with replacement\n",
    "                        n_samples=1000,   # to match majority class\n",
    "                        random_state=123) # reproducible results\n",
    "        # Combine majority class with upsampled minority class\n",
    "        df_balanced = pd.concat([df_balanced, temp])\n",
    "    Y_data = df_balanced['cell_type_idx']\n",
    "    Y_data.fillna(0,inplace=True)\n",
    "    X_data = df_balanced.drop(\"cell_type_idx\", axis = 1)\n",
    "    X_data.fillna(0,inplace=True)\n",
    "    return df_balanced,X_data,Y_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame,X_data,Y_data = data_inyection_module(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = resample(dataFrame[df['cell_type_idx']==0],\n",
    "                      replace=True,     \n",
    "                      n_samples=1000,  \n",
    "                      random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_data))\n",
    "print(len(Y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudio de la propuesta de red y ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "\n",
    "#Clasificador basado en K-Best\n",
    "test = SelectKBest(score_func=f_classif, k='all')\n",
    "fit = test.fit(X_data, Y_data)\n",
    "print([\"dx_type\",\"age\",\"sex\",\"location\"])\n",
    "print(fit.scores_)\n",
    "\n",
    "#Clasificador basado en arboles\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X_data, Y_data)\n",
    "print(model.feature_importances_)\n",
    "\n",
    "#Clasificador basado en regresión logística\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 1)\n",
    "fit = rfe.fit(X_data, Y_data)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=X_data.drop(\"sex\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_data,Y_data,test_size=0.40,random_state=123)\n",
    "x_test,x_validation,y_test,y_validation = train_test_split(x_test,y_test,test_size=0.50,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeBlock(n_neurons,bachnorm = True,dropout = 0.2):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_neurons))\n",
    "\n",
    "    if bachnorm:\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    if dropout > 0:\n",
    "        model.add(tf.keras.layers.Dropout(dropout))\n",
    "  \n",
    "    model.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    return model\n",
    "def codeBlock(n_neurons,dropout = 0.2):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(n_neurons))\n",
    "\n",
    "    if dropout > 0:\n",
    "        model.add(tf.keras.layers.Dropout(dropout))\n",
    "  \n",
    "    model.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=[3])\n",
    "\n",
    "x = inputs\n",
    "\n",
    "x = codeBlock(16)(x)\n",
    "x = codeBlock(64)(x)\n",
    "x = decodeBlock(16,bachnorm=False,dropout = 0.15)(x)\n",
    "\n",
    "last = tf.keras.layers.Dense(units = 7, activation = 'softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=last)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                           patience = 12,\n",
    "                                           mode = 'min')\n",
    "\n",
    "ams_grad = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=4, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se ha decidido realizar un test rápido con un modelo de Keras para asegurar que\n",
    "#el comportamiento de nuestra red no es fallo de la arquitectura de esta\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "print(knn.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    model.compile(optimizer = ams_grad, loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "    history = model.fit(x_train, y_train ,validation_data=(x_validation, y_validation),epochs = 200,batch_size = 16,verbose = 0,callbacks = [callback,reduce_lr])\n",
    "    model.evaluate(x_test,y_test)\n",
    "print(\"finish\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vgg16vs19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
