{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsBFD7icF6Xc"
   },
   "source": [
    "# Experimento 8 : Ensamblaje de modelos.\n",
    "\n",
    "En este experimento se estudiarán los beneficios de usar modelos ensamblados. La idea inicial surge de (Harangi et al., 2018) donde se propone un ensamblaje formado por AlexNet, VGGNet y GoogLeNet. \n",
    "\n",
    "Los resultados del estudio incentivan el uso de esta estrategia para conseguir precisión extra.\n",
    "\n",
    "La hipótesis que se pretende validar en este estudio es:\n",
    "\n",
    "- La mejora de la precisión derivada del ensamblaje de modelos justifica el incremento de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RxC7JJwlFuvk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pkqu4FPPGQgV"
   },
   "source": [
    "## Definición de rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CZazLFjjGZVf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antgarnie/Escritorio/TFG/Datos\n",
      "/home/antgarnie/Escritorio/TFG/Datos/HAM10000_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "#Rutas de los datos.\n",
    " \n",
    "data_dir = os.path.dirname(os.path.realpath(\"../TFG/Datos/HAM10000_metadata.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "csv_path = os.path.realpath(data_dir + \"/HAM10000_metadata.csv\")\n",
    "\n",
    "#Variables globales\n",
    "\n",
    "altura = 128\n",
    "longitud = 128\n",
    "clases = 7\n",
    "\n",
    "\n",
    "print(data_dir)\n",
    "\n",
    "print(csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD9w48fEGfkF"
   },
   "source": [
    "## Creación del marco de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "pf0IBVhhGehu",
    "outputId": "af59739a-413e-4a7d-c5ac-b775ab675e5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>cell_type_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>/home/antgarnie/Escritorio/TFG/Datos/HAM10000_...</td>\n",
       "      <td>Benign keratosis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "                                                path          cell_type  \\\n",
       "0  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "1  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "2  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "3  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "4  /home/antgarnie/Escritorio/TFG/Datos/HAM10000_...  Benign keratosis    \n",
       "\n",
       "   cell_type_idx  \n",
       "0              2  \n",
       "1              2  \n",
       "2              2  \n",
       "3              2  \n",
       "4              2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inicializando el dataFrame\n",
    "\n",
    "dataFrame=pd.read_csv(csv_path)\n",
    "\n",
    "#Mezclando carpetas.\n",
    "\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "\n",
    "# Inicializando diccionario de categorías\n",
    "\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "#Añadiendo columnas al dataFrame para que sea más legible.\n",
    "\n",
    "dataFrame['path'] = dataFrame['image_id'].map(imageid_path_dict.get)\n",
    "dataFrame['cell_type'] = dataFrame['dx'].map(lesion_type_dict.get) \n",
    "dataFrame['cell_type_idx'] = pd.Categorical(dataFrame['cell_type']).codes\n",
    "dataFrame.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT1Py3CnE0bT",
    "outputId": "aea7fc1b-b1d9-42af-caa5-40293bbc2136"
   },
   "source": [
    "## Preparación de la red\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_network(nn_base_arch):\n",
    "\n",
    "    #Familia VGG\n",
    "    if nn_base_arch == 'VGG16':\n",
    "        nn = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))   \n",
    "    if nn_base_arch == 'VGG19':  \n",
    "        nn = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    \n",
    "    #Familia MobileNet\n",
    "    if nn_base_arch == 'MNv1':\n",
    "        nn = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    if nn_base_arch == 'MNv2':\n",
    "        nn = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "        \n",
    "        \n",
    "    #Entradas mayor de 75 x 75    \n",
    "    if nn_base_arch == 'IV3':\n",
    "        nn = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "        \n",
    "    #Entradas  mayor de 72 x 72\n",
    "    if nn_base_arch == 'Xception':\n",
    "        nn = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "          \n",
    "    if nn_base_arch == 'ENB4':\n",
    "        nn = tf.keras.applications.EfficientNetB4(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    if nn_base_arch == 'ResNet50':  \n",
    "        nn = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    \n",
    "    if nn_base_arch == 'ResNet152v2':  \n",
    "        nn = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(altura, longitud,3))\n",
    "    \n",
    "    return nn\n",
    "\n",
    "def build(nn):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(nn)\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(tf.keras.layers.PReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(clases,activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 22,852,519\n",
      "Trainable params: 22,818,087\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 15,764,423\n",
      "Trainable params: 15,764,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn_base_arch = 'IV3'\n",
    "nn = select_network(nn_base_arch)\n",
    "modelIV3 = build(nn)\n",
    "\n",
    "nn_base_arch = 'VGG16'\n",
    "nn = select_network(nn_base_arch)\n",
    "modelVGG = build(nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembled_models(modelIV3,modelVGG,clases = 7,input_shape=(128, 128, 3)):\n",
    "    image = tf.keras.layers.Input(shape=input_shape)\n",
    "    x  =  modelIV3(image)\n",
    "    x1 = modelVGG(image)\n",
    "    \n",
    "\n",
    "    x = tf.keras.layers.concatenate([x,x1])    #Modificar esta capa en función del caso de estudio\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Dense(clases,activation='softmax')(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=image, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "657/657 [==============================] - 93s 141ms/step - loss: 1.6867 - accuracy: 0.3210 - val_loss: 1.4136 - val_accuracy: 0.4252\n",
      "Epoch 2/20\n",
      "657/657 [==============================] - 93s 142ms/step - loss: 1.3466 - accuracy: 0.4671 - val_loss: 1.1196 - val_accuracy: 0.6088\n",
      "Epoch 3/20\n",
      "657/657 [==============================] - 93s 142ms/step - loss: 1.1123 - accuracy: 0.5947 - val_loss: 0.8707 - val_accuracy: 0.7286\n",
      "Epoch 4/20\n",
      "657/657 [==============================] - 95s 144ms/step - loss: 0.9752 - accuracy: 0.6641 - val_loss: 0.7343 - val_accuracy: 0.7463\n",
      "Epoch 5/20\n",
      "657/657 [==============================] - 96s 146ms/step - loss: 0.7826 - accuracy: 0.7216 - val_loss: 0.5823 - val_accuracy: 0.7626\n",
      "Epoch 6/20\n",
      "657/657 [==============================] - 94s 144ms/step - loss: 0.6554 - accuracy: 0.7477 - val_loss: 0.5227 - val_accuracy: 0.7884\n",
      "Epoch 7/20\n",
      "657/657 [==============================] - 92s 140ms/step - loss: 0.6119 - accuracy: 0.7687 - val_loss: 1.4112 - val_accuracy: 0.5503\n",
      "Epoch 8/20\n",
      "657/657 [==============================] - 93s 142ms/step - loss: 0.8414 - accuracy: 0.7060 - val_loss: 0.6940 - val_accuracy: 0.7510\n",
      "Epoch 9/20\n",
      "657/657 [==============================] - 92s 140ms/step - loss: 0.6833 - accuracy: 0.7454 - val_loss: 0.5361 - val_accuracy: 0.7891\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.5501 - accuracy: 0.7886\n"
     ]
    }
   ],
   "source": [
    "model = ensembled_models(modelIV3,modelVGG,clases = 7,input_shape=(128, 128, 3))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, mode = 'min') \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model = model.fit(x_train, y_train,validation_data=(x_validation, y_validation),epochs=20,callbacks=[earlyStopping],batch_size = BATCH_SIZE)\n",
    "evaluation = model.model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de balaceo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NO6Snfw-KYe4"
   },
   "outputs": [],
   "source": [
    "def balanced_dataset(df):\n",
    "    df_balanced = pd.DataFrame()\n",
    "    #df = pd.DataFrame()\n",
    "    \n",
    "    for cat in df['cell_type_idx'].unique():\n",
    "        temp = resample(df[df['cell_type_idx'] == cat], \n",
    "                        replace=True,     # sample with replacement\n",
    "                        n_samples=10,   # to match majority class\n",
    "                        random_state=123) # reproducible results\n",
    "\n",
    "        # Combine majority class with upsampled minority class\n",
    "        df_balanced = pd.concat([df_balanced, temp])\n",
    " \n",
    "    df_balanced['cell_type'].value_counts()\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "def load_img_data(size, df, balanced=False):\n",
    "    \"\"\"\n",
    "        ..\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    img_h, img_w = size, size\n",
    "    imgs = []\n",
    "    \n",
    "    if balanced:\n",
    "        df = balanced_dataset(df)\n",
    "    \n",
    "    image_paths = list(df['path'])\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        img = img.astype(np.float32) / 255.\n",
    "        #img = np.asarray(Image.open(image_paths[i]).resize((size,size)))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    #imgs = imgs.astype(np.float32) / 255.\n",
    "    \n",
    "    return imgs, df['cell_type_idx'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos y creamos los casos a experimentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_general_data():\n",
    "    \n",
    "    imgs, target = load_img_data(altura, dataFrame, balanced=True)\n",
    "    \n",
    "    x_train, x_transferLearning, y_train, y_transferLearning = train_test_split(imgs, target, test_size=0.60)\n",
    "       \n",
    "    source_data = [ x_transferLearning , y_transferLearning ]\n",
    "    target_data = [ x_train , y_train ]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(target_data[0], target_data[1], test_size=0.70)\n",
    "    \n",
    "    train_data = [x_train,y_train]\n",
    "    test_data = [x_test,y_test]\n",
    "    \n",
    "    return source_data,train_data,test_data\n",
    "\n",
    "\n",
    "def get_data_for_ex(source_data,train_data,test_data):\n",
    "    \n",
    "    x_train = source_data[0]\n",
    "    y_train = source_data[1]\n",
    "    \n",
    "    x_retrain = train_data[0]\n",
    "    y_retrain = train_data[1]\n",
    "    \n",
    "    percent = math.floor(len(test_data[0])/100*30)\n",
    "       \n",
    "    x_validation = test_data[0][0:percent]\n",
    "    y_validation = test_data[1][0:percent]\n",
    "    \n",
    "    \n",
    "    x_test = test_data[0][percent:-1]\n",
    "    y_test = test_data[1][percent:-1]\n",
    "    \n",
    "    return x_train,x_retrain,x_test,x_validation,y_train,y_retrain,y_test,y_validation\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "# Definimos 7 experimentos cada uno con un optimizador distingo y definimos el número de iteraciones          #\n",
    "###############################################################################################################\n",
    "\n",
    "ITERATIONS_PER_EXP = 5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE=0.0001\n",
    "\n",
    "\n",
    "def set_hiper_to_exp(BATCH_SIZE,EPOCHS,LEARNING_RATE):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE,amsgrad=True)  \n",
    "    return BATCH_SIZE,EPOCHS,opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 146.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_data,train_data,test_data = load_general_data()\n",
    "x_train,x_retrain,x_test,x_validation,y_train,y_retrain,y_test,y_validation = get_data_for_ex(source_data,train_data,test_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Vgg16vs19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
